# ASCII (American Standard Code for Information Interchange)
ASCII (American Standard Code for Information Interchange) is the most common character encoding format for text data in computers and on the internet. In standard ASCII-encoded data, there are unique values for 128 alphabetic, numeric or special additional characters and control codes. ASCII, a standard data-encoding format for electronic communication between computers. ASCII assigns standard numeric values to letters, numerals, punctuation marks, and other characters used in computers.

Before ASCII was developed, different makes and models of computers could not communicate with one another. Each computer manufacturer represented alphabets, numerals, and other characters in its own way.

ASCII was originally developed for teleprinters, or teletypewriters, but it eventually found wide application in personal computers (PCs), beginning with IBM’s first PC, in 1981. ASCII uses seven-digit [**binary numbers**](https://en.wikipedia.org/wiki/Binary_number)—i.e., numbers consisting of various sequences of 0’s and 1’s. Since there are 128 different possible combinations of seven 0’s and 1’s, the code can represent 128 different characters. The binary sequence 1010000, for example, represents an uppercase P, while the sequence 1110000 represents a lowercase p.

Digital computers use a binary code that is arranged in groups of eight, rather than seven, digits, or bits; each such eight-bit group is called a byte. Consequently, ASCII is commonly embedded in an eight-bit field, which consists of the seven information bits and a [**parity bit**](https://en.wikipedia.org/wiki/Parity_bit#:~:text=Parity%20bits%20are%20generally%20applied,string%20is%20even%20or%20odd.) that is used for error checking or for representing special symbols. This eight-bit system increases the number of characters ASCII can represent to 256, and it ensures that all special characters, as well as characters from other languages, can be represented. Extended ASCII, as the eight-bit code is known, was introduced by IBM in 1981 for use in its first PC, and it soon became the industry standard for personal computers. In extended ASCII, 32 code combinations are used for machine and control commands, such as “start of text,” “carriage return,” and “form feed.” Control commands do not represent printable information, but rather they help control devices, such as printers, that may use ASCII. For example, the binary sequence 00001000 represents “backspace.” Another group of 32 combinations is used for numerals and various punctuation marks, another for uppercase letters and a few other punctuation marks, and yet another for lowercase letters.

However, even extended ASCII does not include enough code combinations to support all written languages. Asian languages, for instance, require thousands of characters. This limitation gave rise to new encoding standards—Unicode and UCS (Universal Coded Character Set)—that can support all the principal written languages. Because it incorporates ASCII as its first 128 code combinations, Unicode (specifically UTF-8) is backward-compatible with ASCII while also representing many characters that ASCII cannot. Unicode, which was introduced in 1991, saw its usage jump sharply in the first decade of the 21st century, and it became the most common character-encoding system on the World Wide Web.

## Table of Contents:
- [ASCII Chart](https://github.com/nitishhsinghhh/Tips-and-Tricks-for-Programming-using-Cpp/tree/main/ASCII/ASCIIChart)
- [Input Validation using ASCII](https://github.com/nitishhsinghhh/Tips-and-Tricks-for-Programming-using-Cpp/tree/main/ASCII/InputValidation)
- [Add two characters](https://github.com/nitishhsinghhh/Tips-and-Tricks-for-Programming-using-Cpp/tree/main/ASCII/performingASCIIcalculations)
- [Sorting and Comparison Operations](https://github.com/nitishhsinghhh/Tips-and-Tricks-for-Programming-using-Cpp/tree/main/ASCII/sortingComparisonOperations)
